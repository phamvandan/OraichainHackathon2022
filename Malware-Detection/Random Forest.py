#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Aug 30 01:11:42 2018

@author: alex
"""

#Random Forest

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import pickle


# Importing the dataset
dataset = pd.read_csv('data.csv', sep = '|')
X = dataset.drop(['Name', 'md5', 'legitimate'], axis = 1).values
y = dataset['legitimate'].values

# new_sample = dataset.sample(n = 10)
# new_sample = new_sample.drop(['legitimate'], axis = 1)
# new_sample.to_csv('demo.csv', index=False)

# # Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
filename = 'StandardScaler.sav'
pickle.dump(sc, open(filename, 'wb'))

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)
acc = classifier.score(X_test, y_test)
print('ACC=', acc)
# save the model to disk
filename = 'RandomForest.sav'
pickle.dump(classifier, open(filename, 'wb'))